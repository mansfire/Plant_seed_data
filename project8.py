# -*- coding: utf-8 -*-
"""project8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1imaCaba0mhfXbCi9ZuRu72XRVUXJ8gnR
"""

from google.colab import drive
drive.mount('/content/drive') #'import' and mount my drive so we can get data and image sets

"""Now let's import all needed libraries"""

#Reading the training images from the path and labelling them into the given categories
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2 # this is an important module to get imported which may even cause issues while reading the data if not used
import os
import seaborn as sns # for data visualization
import tensorflow as tf
import keras
import os
from tensorflow.keras.models import Sequential #sequential api for sequential model
from tensorflow.keras.layers import Dense, Dropout, Flatten #importing different layers
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Input, LeakyReLU,Activation
from tensorflow.keras import backend as K
from tensorflow.keras.utils import to_categorical #to perform one-hot encoding
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from tensorflow.keras.optimizers import RMSprop,Adam #optimiers for optimizing the model
from tensorflow.keras.callbacks import EarlyStopping  #regularization method to prevent the overfitting
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras import losses, optimizers
from google.colab.patches import cv2_imshow
from PIL import Image
from tensorflow.keras.preprocessing import image

"""Load dataset and Summary
- Read the dataset properly -Print the overview of the data (shape, checking the proportion of each class) - Plot the images from each class and print their corresponding labels.

Import X (pictures) and Y (labels)
"""

images=np.load('/content/drive/MyDrive/images.npy',encoding='bytes')

labels=pd.read_csv('/content/drive/MyDrive/Labels.csv')

"""See the shape of the data"""



labels.shape

"""We have 4,750 total samples each is 128 by 128 pixels and is RGB (thats the 3 at the end)

Find count of each plant
"""

shape_count=labels.value_counts()
print(shape_count)

"""Not balanced but there are hundreds of each. If maize and wheat are similiar we may see misclassification between them more often due to small sample

Seems to be colored with 4750 images, each is 128 by 128 pixels

Print out 3 images from each class
"""

lab=labels['Label']

u_labels=lab.unique()
u_labels#see the labels we have

cranesbill_img = lab[lab==u_labels[0]].index        # Looping over the path of each image from the Small-flowered Cranesbil directory
hen_img = lab[lab==u_labels[1]].index   # Looping over the path of each image from the Fat Hen directory
purse_img = lab[lab==u_labels[2]].index            # Looping over the path of each image from the Shepherds Purse directory
wheat_img = lab[lab==u_labels[3]].index          # Looping over the path of each image from the  Common wheat directory
chickweed_img = lab[lab==u_labels[4]].index            # Looping over the path of each image from the Common Chickweed directory
charlock_img = lab[lab==u_labels[5]].index           # Looping over the path of each image from the Charlock directory
cleavers_img = lab[lab==u_labels[6]].index          # Looping over the path of each image from the Cleavers directory
mayweed_img = lab[lab==u_labels[7]].index          # Looping over the path of each image from the Scentless Mayweed directory
beet_img = lab[lab==u_labels[8]].index           # Looping over the path of each image from the Sugar beet directory
maize_img = lab[lab==u_labels[9]].index          # Looping over the path of each image from the Maize directory
grass_img = lab[lab==u_labels[10]].index           # Looping over the path of each image from the Black-grass directory
bent_img = lab[lab==u_labels[11]].index           # Looping over the path of each image from the Loose Silky-bent directory

# Ranodmly selecting 3 images from each category
select_cranesbill = np.random.choice(cranesbill_img, 3, replace = False)
select_hen = np.random.choice(hen_img, 3, replace = False)
select_purse = np.random.choice(purse_img, 3, replace = False)
select_wheat = np.random.choice(wheat_img, 3, replace = False)
select_chickweed = np.random.choice(chickweed_img, 3, replace = False)
select_charlock = np.random.choice(charlock_img, 3, replace = False)
select_cleavers = np.random.choice(cleavers_img, 3, replace = False)
select_mayweed = np.random.choice(mayweed_img, 3, replace = False)
select_beet = np.random.choice(beet_img, 3, replace = False)
select_maize = np.random.choice(maize_img, 3, replace = False)
select_grass = np.random.choice(grass_img, 3, replace = False)
select_bent = np.random.choice(bent_img, 3, replace = False)

"""Plot now

Some are similiar but mostly they eem unique. The blue rocks in the background may be a point of confusion

Perform an Exploratory Data Analysis on the images
- Plot the mean images for each class - Any other exploratory deep dive
"""

def find_mean_img(full_mat):
    # calculate the average
    mean_img = np.mean(full_mat, axis = 0)
    # reshape it back to a matrix
    mean_img = mean_img.reshape((150,150))

    return mean_img

CATEGORIES=labels['Label'].unique()
d={ i:[] for i in CATEGORIES}

for i in labels.index:
  gray = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)
  gray = cv2.resize(gray,(150,150))
  d[labels['Label'][i]].append(gray)

l=[]
for i in d.keys():
  l.append(find_mean_img(d[i]))

plt.subplots(figsize=(12,12))
for i in range(len(l)):
    plt.subplot(3,4,i + 1,title='Average '+list(d.keys())[i])
    plt.imshow(l[i])
    plt.axis('off')

"""Illustrate the insights based on EDA
-Key meaningful observations from EDA

The images are much blurrier than before, onviously. It may be harder for use as humans to see thw difference here, but some can be seen. We seen blakc-grass has almost no green while others are very green Some are verys imilar (example charlock and shephard's purse and we may see these misclassified

Data Pre - Processing
-Remove unwanted noise from the images using Guassian Blurring -Apply the normalization -Plot the images before and after the pre-processing steps ( Blurring & Normalization ) -Split the data into train and test
"""

new_train = []
sets = []; getEx = True
for i in images:
    blurr = cv2.GaussianBlur(i,(5,5),0)
    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV) #Using BGR TO HSV conversion. reason is mentioned above
    #HSV Bou daries for the Green color (GREEN PARAMETERS)
    lower = (25,40,50)
    upper = (75,255,255)
    mask = cv2.inRange(hsv,lower,upper) # create a mask
    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11)) #getting structring element ( kernal) of sie 11x11
    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc) # applying morphological transformation ( closing operation ) to remove imperfections from the binary image ( mask)
    boolean = mask>0
    new = np.zeros_like(i,np.uint8)
    new[boolean] = i[boolean]
    new_train.append(new)
    if getEx:
        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL
        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED
        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED
        plt.subplot(2,3,4);plt.imshow(mask) # MASKED
        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED
        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE
        plt.show()
        getEx = False
new_train = np.asarray(new_train)
print("# CLEANED IMAGES")
for i in range(8):
    plt.subplot(2,4,i+1)
    plt.imshow(new_train[i])

"""Seems to work really well

Normalize the data
"""

x_norm=[]
# Normalize image data.
new_train_norm = new_train / 255
plt.subplot(2,2,1);plt.imshow(new_train[0]) # plotting the ORIGINAL IMAGE
plt.title('Blurred')
plt.axis('off')
plt.subplot(2,2,2);plt.imshow(new_train_norm[0]) # plotting the BLURRED IMAGE
plt.title('Blurred and normalized')
plt.axis('off')

new_train=new_train_norm

# Convert labels from digits to one hot vectors.

from sklearn.preprocessing import LabelBinarizer
enc = LabelBinarizer()
y = enc.fit_transform(labels)
print(y.shape)
print(new_train.shape)

"""It worked, we just don't see it in the images"""

from sklearn.model_selection import train_test_split
seed=7
X_train, X_test, y_train, y_test = train_test_split(new_train,y , test_size=0.1, random_state=seed,stratify=y)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

pd.DataFrame(y_train.argmax(axis=1)).value_counts()/pd.DataFrame(y_train.argmax(axis=1)).value_counts().sum()

pd.DataFrame(y_test.argmax(axis=1)).value_counts()/pd.DataFrame(y_test.argmax(axis=1)).value_counts().sum()

from keras.utils.np_utils import to_categorical # convert to one-hot-encoding
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalMaxPooling2D
from keras.optimizers import RMSprop
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam

# Set the CNN model
batch_size=None


model = Sequential()

model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',
                 activation ='relu', batch_input_shape = (batch_size,128, 128, 3)))


model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',
                 activation ='relu'))
model.add(MaxPool2D(pool_size=(2,2)))
model.add(Dropout(0.2))


model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',
                 activation ='relu'))
model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'same',
                 activation ='relu'))
model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))
model.add(Dropout(0.3))

model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',
                 activation ='relu'))
model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',
                 activation ='relu'))
model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))
model.add(Dropout(0.4))



model.add(GlobalMaxPooling2D())
model.add(Dense(128, activation = "relu"))
model.add(Dropout(0.5))
model.add(Dense(12, activation = "softmax"))
model.summary()

#Defining thr optimizer and loss function
optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
model.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics = ["accuracy"])

# fitting the model with epochs = 50
history=model.fit(X_train, y_train, epochs = 50, validation_split=0.1,batch_size = batch_size)

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right');

# Evaluate the model.

score = model.evaluate(X_test, y_test, verbose=0, batch_size = 38)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

from keras.callbacks import ReduceLROnPlateau

learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',
                                            patience=3,
                                            verbose=1,
                                            factor=0.5,
                                            min_lr=0.00001)
epochs = 30
batch_size = 38

# With data augmentation to prevent overfitting (accuracy 0.99286)

datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.1, # Randomly zoom image
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images


datagen.fit(X_train)

from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X_train,y_train , test_size=0.1, random_state=seed,stratify=y_train)
X_train.shape

# Set the CNN model
batch_size=None
model1 = Sequential()

model1.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',
                 activation ='relu', batch_input_shape = (batch_size,128, 128, 3)))


model1.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',
                 activation ='relu'))
model1.add(MaxPool2D(pool_size=(2,2)))
model1.add(Dropout(0.2))


model1.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',
                 activation ='relu'))
model1.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'same',
                 activation ='relu'))
model1.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))
model1.add(Dropout(0.3))

model1.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',
                 activation ='relu'))
model1.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',
                 activation ='relu'))
model1.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))
model1.add(Dropout(0.4))



model1.add(GlobalMaxPooling2D())
model1.add(Dense(256, activation = "relu"))
model1.add(Dropout(0.5))
model1.add(Dense(12, activation = "softmax"))
model1.summary()

#Defining thr optimizer and loss function
optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
model1.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics = ["accuracy"])

#Fitting the model using fit_generator function
#X_train, X_val, y_train, y_test
batch_size = 38
history1 = model1.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),
                              epochs = epochs, validation_data = (X_val,y_val),
                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size
                              , callbacks=[learning_rate_reduction])

plt.plot(history1.history['accuracy'], label='accuracy')
plt.plot(history1.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right');

# Evaluate the model.

score = model1.evaluate(X_test, y_test, verbose=0, batch_size = 38)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# Convert validation observations to one hot vectors
Y_true = np.argmax(y_test, axis=1)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

conf_mat = confusion_matrix(Y_true, result)

df_cm = pd.DataFrame(conf_mat, index = [i for i in range(0, 12)],
                  columns = [i for i in range(0, 12)])
plt.figure(figsize = (10,7))
sns.heatmap(df_cm, annot=True, fmt='g');

